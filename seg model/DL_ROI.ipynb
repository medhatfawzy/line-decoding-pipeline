{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "These are the important imports and functions used in the detection part of the project\n",
    "assuming the other libraries are already installed and imported like cv2, numpy, etc.\n",
    "'''\n",
    "from fastai.vision.all import *\n",
    "from fastai.metrics import accuracy\n",
    "from fastseg import MobileV3Small\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The functions needed for the detection part\n",
    "def get_pred_for_mobilenet(model, img_array): # this is to make sure that the model is in the GPU\n",
    "    with torch.no_grad():\n",
    "        # image_tensor = np.expand_dims(img_array, -1).transpose(2, 0, 1).astype('float32') / 255\n",
    "        image_tensor = img_array.transpose(2, 0, 1).astype('float32') / 255\n",
    "        x_tensor = torch.from_numpy(image_tensor).to(\"cuda\").unsqueeze(0)\n",
    "        model_output = F.softmax(model.forward(x_tensor), dim=1).cpu().numpy()\n",
    "    return model_output\n",
    "\n",
    "def extract_lane_boundaries(left_mask, right_mask, threshold=0.3):\n",
    "    left_boundary = (left_mask > threshold).astype(np.uint8)\n",
    "    right_boundary = (right_mask > threshold).astype(np.uint8)\n",
    "\n",
    "    contours, _ = cv2.findContours(left_boundary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) > 0:\n",
    "        left_boundary = cv2.drawContours(left_boundary, contours, -1, (1), thickness=cv2.FILLED)\n",
    "\n",
    "    contours, _ = cv2.findContours(right_boundary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) > 0:\n",
    "        right_boundary = cv2.drawContours(right_boundary, contours, -1, (1), thickness=cv2.FILLED)\n",
    "\n",
    "    return left_boundary, right_boundary\n",
    "\n",
    "def lane_detection_pipeline(img, model_path=\"seg_model.pth\"):\n",
    "    # Load the model\n",
    "    model = torch.load(model_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "    # Get predictions\n",
    "    back, left, right = get_pred_for_mobilenet(model, img)[0]\n",
    "\n",
    "    # Extract left and right boundaries\n",
    "    left_boundary, right_boundary = extract_lane_boundaries(left, right)\n",
    "\n",
    "    # Create ROI mask\n",
    "    # roi_mask = (left_boundary | right_boundary).astype(np.uint8)\n",
    "\n",
    "    # # Create a copy of the original image\n",
    "    # image_with_roi = np.copy(img)\n",
    "\n",
    "    # # Set all pixels outside the ROI to black\n",
    "    # image_with_roi[roi_mask == 0] = [0, 0, 0]\n",
    "\n",
    "    # # Overlay the left and right lane boundaries in red color\n",
    "    # image_with_roi[left_boundary > 0] = [255, 0, 0]\n",
    "    # image_with_roi[right_boundary > 0] = [0, 255, 0]\n",
    "\n",
    "    # Find the coordinates of the left and right boundaries\n",
    "    left_y, left_x = np.where(left_boundary > 0)\n",
    "    right_y, right_x = np.where(right_boundary > 0)\n",
    "\n",
    "    # Create a black background mask with the same dimensions as the image\n",
    "    mask = np.zeros_like(img, dtype=np.uint8)\n",
    "\n",
    "    # Create a polygon for the left boundary\n",
    "    left_polygon = np.column_stack((left_x, left_y))\n",
    "\n",
    "    # Create a polygon for the right boundary (reverse the order to close the gap)\n",
    "    right_polygon = np.column_stack((right_x[::-1], right_y[::-1]))\n",
    "\n",
    "    # Combine the left and right polygons to fill the region between them\n",
    "    polygon_points = np.vstack((left_polygon, right_polygon))\n",
    "\n",
    "    # Use fillPoly to fill the region between the left and right boundaries\n",
    "    try:\n",
    "        cv2.fillPoly(mask, [polygon_points], (255, 255, 255))\n",
    "    except Exception as e:\n",
    "        print(f\"Error in cv2.fillPoly: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Bitwise-AND your original image and the mask\n",
    "    result = cv2.bitwise_and(img, mask)\n",
    "\n",
    "    # Save the resulting image\n",
    "    # cv2.imwrite(save_path, result)\n",
    "    return result, left, right\n",
    "\n",
    "    # return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_img(img):\n",
    "    # https://nikolasent.github.io/opencv/2017/05/07/Bird's-Eye-View-Transformation.html\n",
    "    IMAGE_H = img.shape[0]\n",
    "    IMAGE_W = img.shape[1]\n",
    "    src = np.float32(\n",
    "        [[0, IMAGE_H], [IMAGE_W, IMAGE_H], [0, IMAGE_H // 10], [IMAGE_W, IMAGE_H // 10]]\n",
    "    )\n",
    "    dst = np.float32(\n",
    "        [[IMAGE_W // 2.8, IMAGE_H], [IMAGE_W // 1.8, IMAGE_H], [0, 0], [IMAGE_W, 0]]\n",
    "    )\n",
    "    img = img[int(IMAGE_H // 2):IMAGE_H, :]  # Apply np slicing for ROI crop\n",
    "    M = cv2.getPerspectiveTransform(src, dst)  # The transformation matrix\n",
    "    img = cv2.warpPerspective(img, M, (IMAGE_W, IMAGE_H))  # Image warping\n",
    "    img = img[\n",
    "        int(IMAGE_H // 10) : int(IMAGE_H // 1.3),\n",
    "        int(IMAGE_W // 3) : int(IMAGE_W // 1.7),\n",
    "    ]\n",
    "    return img\n",
    "\n",
    "def warp_img2(img):\n",
    "    IMAGE_H = img.shape[0]\n",
    "    IMAGE_W = img.shape[1]\n",
    "    new_h = 640\n",
    "    new_w = 300\n",
    "    src = np.float32(\n",
    "        [\n",
    "            [0, IMAGE_H], \n",
    "            [IMAGE_W , IMAGE_H], \n",
    "            [int(IMAGE_W // 2.2), int(IMAGE_H // 1.7)], \n",
    "            [int(IMAGE_W // 1.8), int(IMAGE_H // 1.7)],\n",
    "        ]\n",
    "    )\n",
    "    dst = np.float32(\n",
    "        [\n",
    "            [0, new_h], \n",
    "            [new_w, new_h], \n",
    "            [0, 0], \n",
    "            [new_w, 0],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(src, dst)  # The transformation matrix\n",
    "    img = cv2.warpPerspective(img, M, (new_w, new_h))  # Image warping\n",
    "    return img\n",
    "\n",
    "def gaussian_blur(img, kernel_size=(3, 3)):\n",
    "    return cv2.GaussianBlur(img, kernel_size, 0)\n",
    "\n",
    "def canny_edge(img, low_threshold=100, high_threshold=200):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def harris_corner(img):\n",
    "    # img = np.float32(img)\n",
    "    corners = cv2.cornerHarris(img, blockSize=2, ksize=3, k=0.04)\n",
    "    # corners = cv2.dilate(corners, None)\n",
    "    # img[corners > 0.01 * corners.max()] = 255\n",
    "    return corners\n",
    "\n",
    "def dilation(img, kernel_size=(3, 3)):\n",
    "    return cv2.dilate(img, np.ones(kernel_size, np.uint8))\n",
    "\n",
    "def clahe(img, kernel_size=(3, 3)):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    clahe_image = clahe.apply(img)\n",
    "    return clahe_image\n",
    "\n",
    "def detect_hough_lines(img):\n",
    "    return cv2.HoughLinesP(\n",
    "        img, rho=1, theta=np.pi / 180, threshold=20, minLineLength=5, maxLineGap=10\n",
    "    )\n",
    "\n",
    "\n",
    "def draw_hough_lines(img, lines):\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), 255, 3)\n",
    "    return img\n",
    "\n",
    "\n",
    "def detect_correct_mark(img):\n",
    "    contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rects = [cv2.minAreaRect(contour) for contour in contours]\n",
    "\n",
    "    # correct_rects = [rect for rect in rects if min(rect[1][1], rect[1][0]) < img.shape[1] // 2]\n",
    "    # print(f\"# of correct rects: {len(correct_rects)}\")\n",
    "\n",
    "    # d1 = rect[1][0]\n",
    "    # d2 = rect[1][1]\n",
    "    # width = min(rect[1][1], rect[1][0])\n",
    "    # height = max(rect[1][1], rect[1][0])\n",
    "\n",
    "    center_bottom = (img.shape[1] // 2, img.shape[0] // 1.2)\n",
    "    distances = [distance.euclidean(rect[0], center_bottom) for rect in rects]\n",
    "    btm_cntr_rect_idx = np.argmin(distances)\n",
    "\n",
    "    return rects, btm_cntr_rect_idx\n",
    "\n",
    "\n",
    "def draw_rectangle_features(img, rect, idx):\n",
    "    width = min(rect[1][1], rect[1][0])\n",
    "    box = np.intp(cv2.boxPoints(rect))\n",
    "\n",
    "    top_left = box[np.argmax(box[:, 1])] - np.array([0, 50])\n",
    "    bottom_left = box[np.argmin(box[:, 1])] - np.array([0, 50])\n",
    "\n",
    "    cv2.drawContours(img, [box], 0, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.circle(\n",
    "        img,\n",
    "        center=tuple(map(int, rect[0])),\n",
    "        radius=3,\n",
    "        color=(255, 255, 255),\n",
    "        thickness=5,\n",
    "    )\n",
    "\n",
    "    cv2.putText(\n",
    "        img,\n",
    "        text=str(idx),\n",
    "        org=tuple(map(int, top_left)),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale=2,\n",
    "        color=(255, 255, 255),\n",
    "        thickness=3,\n",
    "    )\n",
    "    return img\n",
    "\n",
    "\n",
    "def map_values(\n",
    "    rect: tuple, img: np.ndarray, car_steer: float = 0\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Map the values for the steer to (-1, 1)\n",
    "    and the values for the throttle to (0, 1)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rect: tuple\n",
    "        the rectangle that is used to determine the throttle and steering angle\n",
    "    img: np.ndarray\n",
    "        the image that is used to determine the mapping\n",
    "    Return\n",
    "    ------\n",
    "    throttle: float\n",
    "        the throttle for the car\n",
    "    steer: float\n",
    "        the steering angle for the car\n",
    "    \"\"\"\n",
    "    center = rect[0]\n",
    "    img_center = (img.shape[1] // 2, img.shape[0] // 1.2)\n",
    "\n",
    "    offset = center[0] - img_center[0]  # offset from the center of the image\n",
    "    offset = offset / img.shape[1]  # normalize the offset\n",
    "\n",
    "    d1 = rect[1][0]\n",
    "    d2 = rect[1][1]\n",
    "    width = min(rect[1][1], rect[1][0])\n",
    "    height = max(rect[1][1], rect[1][0])\n",
    "    angle = rect[2]\n",
    "\n",
    "    # rounding to the nearest 5\n",
    "    width = int(5 * round(width / 5))\n",
    "    angle = int(5 * round(angle / 5))\n",
    "\n",
    "    if angle in (0, 90, -0, -90, 0.0, 90.0, -0.0, -90.0):\n",
    "        angle = 0\n",
    "\n",
    "    elif d1 < d2:\n",
    "        angle = 90 - angle\n",
    "\n",
    "    else:\n",
    "        angle = -angle\n",
    "\n",
    "    throttle = max(width / (120 + car_steer), 0.4)  # A trial and error value\n",
    "    steer = angle / (90 + throttle * 100) + (offset)\n",
    "\n",
    "    return throttle, steer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_imgs(imgs, titles):\n",
    "    rows = int(np.ceil(len(imgs) / 3 ))\n",
    "    cols = 3\n",
    "    figsize = (cols * 5, rows * 4)\n",
    "    _, axs = plt.subplots(rows, cols, figsize=figsize)\n",
    "    for img, title, ax in zip(imgs, titles, axs.flatten()):\n",
    "        ax.imshow(img, cmap=\"gray\")\n",
    "        ax.set_title(title)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_process_image(img):\n",
    "    img = warp_img(img)\n",
    "    img_warp = img.copy()\n",
    "    img = gaussian_blur(img)\n",
    "    # img = harris_corner(img)\n",
    "    img = canny_edge(img)\n",
    "    img_canny = img.copy()\n",
    "    img = dilation(img)\n",
    "    img_w, img_h = img.shape[1], img.shape[0]\n",
    "\n",
    "    lines = detect_hough_lines(img)\n",
    "    if lines is None:\n",
    "        return img, np.zeros((img_h, img_w), dtype=np.uint8)\n",
    "\n",
    "    img_hou = np.zeros((img_h, img_w), dtype=np.uint8)\n",
    "    img_hou = draw_hough_lines(img_hou, lines)\n",
    "\n",
    "    rects, bottom_center_rect_idx = detect_correct_mark(img_hou)\n",
    "\n",
    "    throttle, steer = map_values(rects[bottom_center_rect_idx], img_hou)\n",
    "    # return throttle, steer\n",
    "\n",
    "    img_hou = cv2.cvtColor(img_hou, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    center_bottom = (img_hou.shape[1] // 2, img_hou.shape[0] // 1.5)\n",
    "    cv2.circle(\n",
    "        img_hou,\n",
    "        center=tuple(map(int, center_bottom)),\n",
    "        radius=50,\n",
    "        color=(0, 0, 255),\n",
    "        thickness=10,\n",
    "    )\n",
    "    for i, rect in enumerate(rects):\n",
    "        img_hou = draw_rectangle_features(img_hou, rect, idx=i)\n",
    "    \n",
    "    cv2.putText(\n",
    "        img_hou,\n",
    "        text=f\"{bottom_center_rect_idx} SELECTED\",\n",
    "        org=(0, 50),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale=1,\n",
    "        color=(0, 255, 255),\n",
    "        thickness=3,\n",
    "    )\n",
    "    \n",
    "    return img_warp, img_hou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"../imgs/project_video.mp4\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\") or ret == False:\n",
    "        break\n",
    "    result, left, right = lane_detection_pipeline(frame)\n",
    "    # result_warped, result_hou = show_process_image(result)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Lane\", result)\n",
    "    # cv2.imshow(\"Warped\", result_hou)\n",
    "    # time.sleep(0.1)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
